{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c52d7c0-153c-4e09-b5cc-ca9c7928b073",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e6eea-e8e1-4a89-8763-9d15ef30a10d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79269c-aed2-4a0d-b3d3-00c66a2ab290",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd866781-321f-4775-865b-891701bce026",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this project, the attention is not directed towards attributes such as 'smiling' or 'glasses' from the CelebA labels, instead, we’re interested in the identity of datapoints. So, we have chosen to work with 1,000 unique identities. For these identities, we have 27,018 training images and 3,009 test images. You can find the images and their corresponding labels in `./data/trainset.txt` for training data and `./data/testset.txt` for test data.\n",
    "\n",
    "Furthermore, there is a distinct dataset available in `./data/ganset.txt` which is public and is utilized to pretrain the GAN. It's crucial to note that this dataset does not have class overlap with the private data designated for training the classifier, ensuring that the identities in the GAN pretraining set are exclusive from those in the classifier’s training and test sets.\n",
    "\n",
    "to download the CelebA dataset run the cell below.\n",
    "\n",
    "> ### NOTE\n",
    "> There are occasions when downloading the CelebA dataset using `torchvision`\n",
    "> results in a Google Drive error. This is due to the dataset being hosted on\n",
    "> Google Drive, which sometimes restricts the number of download requests.\n",
    ">\n",
    "> In such cases, an alternative is to download the CelebA dataset directly \n",
    "> from Kaggle using the following link:\n",
    "> [CelebA Dataset on Kaggle](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset)\n",
    "> Once downloaded, the CelebA dataset should be added to the `./data` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b1220-dcf2-4c85-9b9a-c29b801e0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_downloader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c96e3-fde7-44bd-af9c-01ccf7cb5770",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb1ec11-635f-4406-b0cb-19f32744be52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ddd24-8cca-4842-ae84-2da598f62965",
   "metadata": {},
   "source": [
    "Here is where we train the target model classifier. We choose 3 sophisticated pre-trained models that have been trained on ImageNet data and then fine-tune them to classify our celebrity identities data. Details on these architectures can be found below. Training details can be found and altered at `./config/classify.json`\n",
    "\n",
    "| Model       | Size (MB) | Parameters | Depth | Time (ms) per inference step (CPU) | Time (ms) per inference step (GPU) |\n",
    "|-------------|-----------|------------|-------|------------------------------------|------------------------------------|\n",
    "| Resnet152   | 232       | 60.4M      | 311   | 127.4                              | 6.5                                |\n",
    "| VGG16       | 528       | 138.4M     | 16    | 69.5                               | 4.2                                |\n",
    "| FaceNet64   | 98        | 25.6M      | 22    | 58.2                               | 4.6                                |\n",
    "\n",
    "\n",
    "> ## Note\n",
    "> You can find pretrained checkpoints of these model backbones and also fune-tuned checkpoints [here](https://drive.google.com/drive/folders/1ZTTrRJr-2HOgfyxndP8a9R2Hb_UOgV6J)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1f300-218e-448f-a63d-4941f1e247a7",
   "metadata": {},
   "source": [
    "### Train a VGG16 based classifier\n",
    "\n",
    "Running the cell below will train a classifier based on the *VGG16* model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b8597-2fdc-4dfb-8bf1-b68694e3b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train_classifier.py --model_name \"VGG16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8427859-4796-4c4c-9eea-8d31920d65d8",
   "metadata": {},
   "source": [
    "### Train a FaceNet based classifier\n",
    "\n",
    "Running the cell below will train a classifier based on the *FaceNet* model.\n",
    "\n",
    "> to train this model you need to download `backbone_ir50_ms1m_epoch120.pth` from [here](https://drive.google.com/drive/folders/1ZTTrRJr-2HOgfyxndP8a9R2Hb_UOgV6J) and add it to `./target_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56478f80-e939-47d9-97d9-fea4b54a4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train_classifier.py --model_name \"FaceNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce832b-de2d-47d0-ae9b-f99af4453a1c",
   "metadata": {},
   "source": [
    "### Train an IR152 based classifier\n",
    "\n",
    "Running the cell below will train a classifier based on the *ResNet-152* model.\n",
    "\n",
    "> to train this model you need to download `Backbone_IR_152_Epoch_112_Batch_2547328_Time_2019-07-13-02-59_checkpoint.pth` from [here](https://drive.google.com/drive/folders/1ZTTrRJr-2HOgfyxndP8a9R2Hb_UOgV6J) and add it to `./target_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feda8bd-d9eb-4e1a-8c97-72cddf790ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train_classifier.py --model_name \"IR152\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a63f4-9ef5-46f6-84db-c3dac8999ffd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb23f21-1884-4118-bfde-7623a37b63f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training General Binary GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599dd11d-6dc8-4314-99f4-914f1ca79a10",
   "metadata": {},
   "source": [
    "Executing the cell below will initiate the training of a general binary GAN, excluding any enhancements mentioned in the paper.. A pretrained checkpoint for this GAN can be accessed [here.](https://drive.google.com/drive/folders/1eCuJXdpKlrIAf9jIYxQ1cHviCQ4hxL--?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64f9ed-b3a0-43f0-9f06-f9bad11c7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run k+1_gan.pyinary_gan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731eb2bc-8d5a-485b-9b04-1a984a80f7de",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e0ff4-2518-4e72-a5b2-3e02b28419f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training an Inversion-Specifi GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a397cb-1c39-48bb-b8b3-ec12a13cceda",
   "metadata": {
    "tags": []
   },
   "source": [
    "Executing the cell will initialize an Inversion-Specific GAN. This is the model proposed in [2], which is the article at the center of my assignment. The --model_name_T flag indicates the target model being attacked here. A pre-trained checkpoint for this GAN can be accessed [here.](https://drive.google.com/drive/folders/1eCuJXdpKlrIAf9jIYxQ1cHviCQ4hxL--?usp=sharing) Additionally, model checkpoints and generated image results are saved in the `./improvedGAN` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef590c-f29e-4ff7-9ce5-b2f3f5ddcccb",
   "metadata": {},
   "source": [
    "### Train a GAN VGG16\n",
    "\n",
    "Train an inversion-specific GAN that attacks VGG16 model.\n",
    "\n",
    "> #### Important Note\n",
    "For training, ensure that the target model, named `VGG16_86.30_allclass.tar`, obtained either from the previous stage or [here](https://drive.google.com/drive/folders/1eCuJXdpKlrIAf9jIYxQ1cHviCQ4hxL--?usp=sharing), is placed at `./target_model/target_ckp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b71252-1f0f-4415-85a1-a8de2f799b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run k+1_gan.py --model_name_T \"VGG16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e669e-c66d-4fb9-97b9-1305f4b811d9",
   "metadata": {},
   "source": [
    "### Attack FaceNet64\n",
    "\n",
    "Train an inversion-specific GAN that attacks FaceNet64 model.\n",
    "\n",
    "> #### Important Note\n",
    "For training, ensure that the target model, named `FaceNet64_88.50.tar`, obtained either from the previous stage or [here](https://drive.google.com/drive/folders/1eCuJXdpKlrIAf9jIYxQ1cHviCQ4hxL--?usp=sharing), is placed at `./target_model/target_ckp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb62489-51c9-45af-8a14-a1eaa536f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run k+1_gan.py --model_name_T \"FaceNet64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7af7c-9130-4865-b09f-8fcb5fb2889d",
   "metadata": {},
   "source": [
    "### Attack IR152\n",
    "\n",
    "Train an inversion-specific GAN that attacks ResNet-152 model.\n",
    "\n",
    "> #### Important Note\n",
    "For training, ensure that the target model, named `IR152_91.16.tar`, obtained either from the previous stage or [here](https://drive.google.com/drive/folders/1eCuJXdpKlrIAf9jIYxQ1cHviCQ4hxL--?usp=sharing), is placed at `./target_model/target_ckp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c14098-1342-4af0-a3d4-653a31b0b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run k+1_gan.py --model_name_T \"IR152\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffbd9a-5151-4d09-84ae-4d0e0f0ac467",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a1ce6-2942-4cb8-a688-1ff791bfe48c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Accuracy and Top 5 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8540574-7814-4736-ae0e-111a0e0fb44b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "This section of the code is where the actual attack is executed. In each cell, one model is selected as the target and subsequently attacked. \n",
    "\n",
    "- The `improved_flag` parameter indicates whether the 'Inversion-Specific GAN', as mentioned in the paper, is being used for the attack.\n",
    "- The `dist_flag` parameter signifies whether distribution recovery is employed or not.\n",
    "\n",
    "If both `improved_flag` and `dist_flag` are set to false, simply the attack is GMI as proposed in felan.\n",
    "\n",
    "We will conduct experiments utilizing various configurations of these flags to ascertain their impact and assess whether their presence influences the results.\n",
    "\n",
    "> #### Important Note\n",
    "> Before executing the cells below, ensure that the model `FaceNet_95.88.tar`, downloaded from [here](https://drive.google.com/drive/folders/1eCuJXdpKlrIAf9jIYxQ1cHviCQ4hxL--?usp=sharing), is located at `./target_model/target_ckp`. This model serves as the Evaluation Classifier. The role of the Evaluation Classifier is explained in the report file.\n",
    "\n",
    "For each attack, we will examine all possible combinations of flags and compare the results, which can be found in the project report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56552dbc-cea3-4dd9-9a31-7a695f92fe48",
   "metadata": {},
   "source": [
    "### Attack VGG16 Bases Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e97d8-ac25-43d7-bf9a-10d2561737a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"VGG16\" --improved_flag --dist_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a998fe-7f69-4af7-9a1f-6bb0059d91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"VGG16\" --improved_flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828cae42-aa7f-4cad-ae10-ee6d5f4e5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"VGG16\" --dist_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4eaf5f-d68c-4a86-9687-9a6a3eaea6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"VGG16\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53bbe13-f385-486b-8bc2-884db1d839c1",
   "metadata": {},
   "source": [
    "### Attack VGG16 FaceNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b95421-d69f-49e7-bdb0-9c75a78aee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"FaceNet64\" --improved_flag --dist_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5909a3-9534-445f-9751-0c464ab49a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"FaceNet64\" --improved_flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467252fb-2c37-4aa8-968f-5c7e927a871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"FaceNet64\" --dist_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648d459-ee89-43d3-be78-a00a58a6f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"FaceNet64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f960751-9279-409b-bbe6-e15637a5c2cd",
   "metadata": {},
   "source": [
    "### Attack IR152 Bases Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12853aec-e329-41e1-83ed-451b2d677db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"IR152\" --improved_flag --dist_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db02ff-8875-4af2-8c3a-da50801d35b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"IR152\" --improved_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358de672-9166-431c-b388-e9311236850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"IR152\" --dist_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732da34-062c-4542-9af8-a78ed9b89ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run recovery.py --model \"IR152\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6da2c-5c15-47f1-b27a-99881190e542",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f2198-47f2-432e-8dd6-bf03b4dd4798",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculating the Fréchet inception distance (FID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb459f-2d68-4198-b2e8-6fc4ad72edce",
   "metadata": {},
   "source": [
    "FID (Fréchet Inception Distance) is a widely recognized method used to evaluate the performance of GANs. In this project, since the original code provided by the authors didn't include a module to calculate FID, i implemented it separately. By executing the provided code, we will be able to calculate the FID for both the GMI model and the Inversion-Specific model to thoroughly analyze their performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dc759-ff0d-4dda-b535-cfee1548f212",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate FID for GMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767e149-7f91-42a6-a664-a3c06808a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run calculate_FID.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62428c31-51c7-4a6f-a54c-fa96dabf786c",
   "metadata": {},
   "source": [
    "### Calculate FID for Inversion-Specific GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad3ef3-ab55-4bf5-8132-8c9e1b61fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run calculate_FID.py --improved_flag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
